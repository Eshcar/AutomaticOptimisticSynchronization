\section{Evaluation}
\label{sec:eval}

In this section we evaluate the performance of our approach on two types of data
structures 1)~supporting only insert delete and get operations (see
Section~\ref{sec:readwrite}), 2)~supporting range queries--retrieve all records
within the range---in addition to the basic single record operations (see
Section~\ref{sec:range}). We compare the performance of our approach in terms of
throughput to fully pessimistic approaches,  applying fine-grain locking. These
algorithms also serve as the lock-based reference implementation at the base of
our semi-optimistic implementations. To complement the evaluation, we also
compare our approach to hand-crafted state-of-the-art implementation of each
data structure.         

We run the experiments on our Intel Xeon E5-4650 processors, 
each with 8 cores for a total of 32 threads 
(with hyper-threading disabled). 
We used Ubuntu 12.04.4 LTS and Java Runtime Environment (build
1.7.0\_51-b13) using the 64-Bit Server VM (build 24.51-b03, mixed mode).


The keys in the experiments are selected uniform at random from the range
$[0,2\cdot10^6]$. We initiate each experiment by pre-filling the data structure until its size is within 5\% of $10^6$records.   

To increase accuracy and reduce variance, each experiment consists of $7$ trials. A trial is a $5$ second run in which each thread continuously executes randomly chosen operations; each trial initiates a new data structure. The presented results are the average throughput over all trials after eliminating outliers.

\subsection{Insert-Delete-Get Operations}
\label{sec:readwrite} 

We start by benchmarking search-tree data structure supporting the basic insert delete and get (lookup) operations. Our experiments evaluate unbalanced as well as balanced trees.

We consider sequential Java implementations of an unbalanced binary
tree~\cite{binary tree source code}, and a treap~\cite{treap source code}. To
generate a pessimistic lock-based implementation we manually synthesize a concurrent code by applying the domination locking technique to both data structures. The resulting algorithms are denoted \domTree and \domTreap. Finally, we manually apply the lock-removal method to the referene implementations to get our semi-optimistic version of the code, which we call \autoTree and \autoTreap, respectively.

We further compare our implementations to their hand-crafted state-of-the-art counterparts. We compare \autoTree to
\begin{itemize}
\item \danaTree - The locked-based 
				unbalanced tree of Drachsler at al.~\cite{DrachslerVY2014}\footnote{Implementation provided by the authors.}. 
\end{itemize}
and \autoTreap is evaluated against three hand-crafted implementations
\begin{itemize}
\item \danaAVL - The locked-based relaxed balanced AVL tree of 
				Drachsler et al.~\cite{DrachslerVY2014}\footnote{Implementation available at \\
				\texttt{https://github.com/logicalordering/trees}}.
\item \bronson - The locked based relaxed balanced AVL tree
				of Bronson et al.~\cite{BronsonCCO2010}\footnote{Implementation available at \\
				\texttt{https://github.com/nbronson/snaptree}}.
\item \skiplist - The non-blocking skip-list by Doug 
				Lea included in the 
				the Java standard library.
\end{itemize}

We evaluate performance in three representative workloads: \emph{read-only}
workload comprising of $100\%$ lookup operations, \emph{write-intensive}
workload comprising of insert and delete operations ($50\%$ each), and
\emph{mixed workload} comprising of $50\%$ lookups, $25\%$ inserts and $25\%$
deletes.

Figure~\ref{evaluation:results:unbalanced} 
shows the throughput of unbalanced data structures and Figure~
\ref{evaluation:results:balanced} shows
the throughput of the balanced ones. We see that our semi-optimistic
solution is far superior to previous, fully-pessimistic, 
automated approaches, with up-to two order of magnitude higher performance
(between x50 in write intensive workload to x70 in read-only workload). It
successfully overcomes the bottlenecks associated with lock contention, and in many scenarios comes close to custom-tailored implementations.

\begin{figure*}
\begin{center}
\input{plots/unbalanced2}
\end{center}
\caption{Throughput of unbalanced data structures.}
\label{evaluation:results:unbalanced}
\end{figure*}


\begin{figure*}
\begin{center}
\input{plots/balanced2}
\end{center}
\caption{Throughput of balanced data
structures.}
\label{evaluation:results:balanced}
\end{figure*}

The results for the read-only workload show the main overhead
of our automatic approach. By profiling the code, we learned 
that the bulk of this overhead stems from the need to track all read objects,
which is inherent to our automatic transformation. 
This is in contrast with the hand-crafted implementations,
which have no overhead on reads in this scenario, thanks to either 
wait-free reads (in \danaTree and \danaAVL), or optimistic validation (in \bronson). 
 
As the ratio of updates in the workload increases, our automatic implementation 
closes this gap.
These results show that our automatic transformation deals well with update contention. 
This might be due to the fact that once
an update phase begins, the operation is not delayed due to concurrent 
read-only operations. 


\subsection{Range Queries}
\label{sec:range} 

This section evaluates the performance of our approach when supporting a more
intricate functionality like range queries. Supporting atomic (linearizable)
range query is challenging and the implementation is often forced to pose an
overhead on the basic insert and delete to allow the range queries to complete.
 
