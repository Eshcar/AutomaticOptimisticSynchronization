\section{Evaluation}
\label{sec:eval}

In this section we evaluate the performance of our approach on two types of data
structures (1)~supporting only insert delete and get operations (see
Section~\ref{sec:readwrite}), (2)~supporting range queries that retrieve all
records within the range in addition to the basic single record operations (see
Section~\ref{sec:range}). We compare the performance of our approach in terms of
throughput to fully pessimistic approaches, applying fine-grain locking. These
algorithms also serve as the lock-based reference implementation at the base of
our semi-optimistic implementations. 
To complement the evaluation, we 
compare our approach to hand-crafted state-of-the-art implementations of each
data structure. 
We also measure the performance of a global lock implementation of the data
structures. In all workloads the results are identical or inferior to the
performance of the pessimistic fine-grain locking implementations. Adding these
results to the figures only obscures the presentation, and hence they are omitted.        

We follow a standard evaluation methodology
(\cite{DrachslerVY2014,NatarajanM2014,BrownER2014,ArbelA2014}). Each experiment
consists of $5$ trials. A trial is a five second run in which each thread continuously executes
randomly chosen operations with respect to the workload distribution. Each trial
begins by initiating a new data structure and applying an untimed pre-filling
phase, which continues until the size of the data structure is within 5\% of
$10^6$ records. The presented results are the average throughput over all trials.    
The keys in each trial and pre-filling phase are selected uniformly at random
from the range $[0,2\cdot10^6]$.
We also experimented with a smaller range ($[0,2\cdot10^4]$) to test different
contention levels; since the results show similar trends they are omitted. 

All implementations are written in Java. We ran the experiments on four Intel
Xeon E5-4650 processors, each with 8 cores for a total of 32 threads 
(with hyper-threading disabled). 
We used Ubuntu 12.04.4 LTS and Java Runtime Environment (build
1.7.0\_51-b13) using the 64-Bit Server VM (build 24.51-b03, mixed mode).

\subsection{Insert-Delete-Get Operations}
\label{sec:readwrite} 

We start by benchmarking search-tree data structure supporting the basic insert
delete and get (lookup) operations. Our experiments evaluate unbalanced as well
as balanced trees.  

We consider textbook sequential implementations of an unbalanced binary
tree, and a treap~\cite{AragonS1989}. To
generate a pessimistic lock-based implementation we synthesize
concurrent code by applying the domination locking technique to the sequential
data structures. The resulting algorithms are denoted \domTree and \domTreap.
Finally, we apply our lock-removal transformation to the reference
implementations to get our semi-optimistic version of the code, which we call
\autoTree and \autoTreap, respectively.     

We further compare our implementations to their hand-crafted state-of-the-art counterparts. We compare \autoTree to
\begin{itemize}
\item \danaTree The locked-based 
				unbalanced tree of Drachsler et
				al.~\cite{DrachslerVY2014}\footnote{Implementation provided by the authors.}.
\end{itemize}
\autoTreap is evaluated against three hand-crafted implementations
\begin{itemize}
\setlength{\itemsep}{0pt}
\setlength{\parskip}{0pt}
\item \danaAVL The locked-based relaxed balanced AVL tree of 
				Drachsler et al.~\cite{DrachslerVY2014}\footnote{Implementation available at \\
				\texttt{https://github.com/logicalordering/trees}}.
\item \bronson The locked based relaxed balanced AVL tree
				of Bronson et al.~\cite{BronsonCCO2010}\footnote{Implementation available at \\
				\texttt{https://github.com/nbronson/snaptree}}.
\item \skiplist The non-blocking skip-list in the 
				the Java standard library; based on the work of
				Fraser and Harris~\cite{fraser2004practical}.
\end{itemize}


We evaluate performance in three representative workloads distributions:
\emph{read-only} workload comprising of $100\%$ lookup operations, \emph{write-dominated}
workload comprising of insert and delete operations ($50\%$ each), and
\emph{mixed workload} comprising of $50\%$ lookups, $25\%$ inserts and $25\%$
deletes.

Figure~\ref{evaluation:results:unbalanced} 
shows the throughput of unbalanced data structures and Figure~\ref{evaluation:results:balanced} shows
the throughput of the balanced ones. We see that our semi-optimistic
solution is far superior to previous, fully-pessimistic, 
automated approaches, with up-to two order of magnitude higher performance
(between x50 in write dominated workload to x70 in read-only workload). It
successfully overcomes the bottlenecks associated with lock contention, and 
specifically the contention on the lock of the root, even if held only for short
periods in the \domTree and \domTreap implementations. In
many scenarios our solution comes close to custom-tailored implementations. 

\begin{figure*}
\begin{center}
\input{plots/unbalanced2}
\end{center}
\caption{Throughput of unbalanced data structures.}
\label{evaluation:results:unbalanced}
\end{figure*}


\begin{figure*}
\begin{center}
\input{plots/balanced2}
\end{center}
\caption{Throughput of balanced data
structures.}
\label{evaluation:results:balanced}
\end{figure*}

The results for the read-only workload show the main overhead
of our automatic approach. By profiling the code, we learned 
that the bulk of this overhead stems from the need to track all read objects,
which is inherent to our transformation. 
This is in contrast with the hand-crafted implementations,
which have small overhead on reads in this scenario, thanks to either 
wait-free reads (in \danaTree and \danaAVL), or optimistic validation (in \bronson). 
 
As the ratio of updates in the workload increases, our automatic implementation 
closes this gap.
These results show that our automatic transformation deals well with update contention. 
This might be due to the fact that once
an update phase begins, the operation is not delayed due to concurrent 
read-only operations. 


\subsection{Range Queries}
\label{sec:range} 

Next we evaluate the performance of our approach when the data
structure supports a more intricate functionality like range queries. Hand
crafting an implementation of a data structure that supports atomic
(linearizable) range queries is challenging.
The implementations that do support iterating through records may impose an
additional overhead on the regular read and write operations to ensure
progress of range queries.
The results in this section demonstrate that our method
allows generating a correct and efficient code, which is otherwise difficult
to obtain.

We use a skip-list that easily supports range queries by the
nature of its linked-structure. The core of the implementation is the key lookup
method; once reaching the key, a record can be added or be removed in place or
an iteration of subsequent records can be executed by traversing
the bottom level linked-list.

The domination locking scheme cannot be efficiently applied to the skip list
structure since it is a DAG rather than a tree structure. Therefore, we need to
manually devise a pessimistic locking protocol. Our
textbook~\cite{HerlihyS2008} algorithm applies hand-over-hand locking of each
level, such that at the end of the search the operation holds locks on two
records in each level, which define the minimal interval within this level that
contains the lookup key (first key in the case of a range query). Once reaching
the bottom level, unnecessary locks are released. Update operations only keep
the locks on nodes that will be modified; while holding these locks any
modification can be executed in isolation from other update operations. Range
queries keep the locks in the level with the minimal interval spanning the
range. The operation uses hand-over-hand locking to traverse through all records
within the range. This pessimistic lock-based algorithm is denoted \domSkiplist. 
As in previous data structures, we  apply the lock-removal method to the
reference implementation to get a semi-optimistic algorithm, which we call
\autoSkiplist.  

\autoSkiplist is compared to \domSkiplist and is further evaluated against two
state-of-the-art data structures which support range queries: \bronson and
\skiplist.
\bronson provides atomic range queries by traversing a clone of the
original tree that is lazily generated,
whereas iterations in Java's concurrent skip list are not
guaranteed to be atomic.

The evaluation of range queries focuses on a mixed workload where half of the
threads are dedicated to performing range queries, and the other half performs a
mix of insert and delete operations (50\% each). 
%\eshcar{what about a workload that includes only 100\% range
%queries?} 
We experiment with queries with big ranges varying between $1000$ to $2000$ keys
(Figure~\ref{evaluation:results:skiplist1000}) and small ranges
between $10$ to $20$
keys (Figure~\ref{evaluation:results:skiplist}).


% \begin{figure*}
% \begin{center}
% \input{plots/range}
% \end{center}
% \caption{Throughput of skip-list operations.}
% \label{evaluation:results:range}
% \end{figure*}

\begin{figure*}
	\begin{center}
	\begin{subfigure}[t]{.35\textwidth}
		\caption{Range queries}
		\input{plots/range1000}
		\label{evaluation:results:range1000}
	\end{subfigure}
	\quad\quad
	\begin{subfigure}[t]{.35\textwidth}
		\caption{Insert and delete operations}
		\input{plots/update1000}
		\label{evaluation:results:update1000}
	\end{subfigure}
	\ref{skiplistLegened1000}
	\end{center}
\caption{Half the threads execute big range queries $[1000,2000]$
and half the threads execute insert and delete operations}
\label{evaluation:results:skiplist1000}
\end{figure*}


\begin{figure*}
	\begin{center}
	\begin{subfigure}[t]{.35\textwidth}
		\caption{Range queries} 
		\input{plots/range}
		\label{evaluation:results:range}
	\end{subfigure}
	\quad\quad
	\begin{subfigure}[t]{.35\textwidth}
		\caption{Insert and delete operations}
		\input{plots/update}
		\label{evaluation:results:update}
	\end{subfigure}
	\ref{skiplistLegened}
	\end{center}
\caption{Half the threads execute small range queries$[10,20]$
and half the threads execute insert and delete operations}
\label{evaluation:results:skiplist}
\end{figure*}

We measure the throughput of range queries and update operations separately,
that is, the overall number of range queries executed per second - reported
in Figures~\ref{evaluation:results:range1000}
and~\ref{evaluation:results:range}, and the overall number of update (insert 
and delete) operations executed per second - reported in
Figures~\ref{evaluation:results:update1000} and~\ref{evaluation:results:update}.

These results demonstrate again that our semi-optimistic
solution is superior to fully-pessimistic fine-grain solution, with up-to two
order of magnitude higher throughput (x75 for small range queries, x4 for small
ranges, and x100 for update operations, regardless of the range size). As in the
domination locking version of the tree data structures, holding a lock on the head sentinel of the skip list in
\domSkiplist, even for short periods, imposes a performance penalty similar to
using a global lock. Put in other words, our transformation generates a DAP
implementation---only locking objects of nodes that are modified by the
operations---from a non-DAP one. The great increase in throughput can
be attributed to this property.

The performance of \autoSkiplist is almost
identical to that of \skiplist, despite the fact that \skiplist performs inconsistent iterations.

Figure~\ref{evaluation:results:range1000}
shows that for big ranges \bronson scales well up to 8 threads, outperforming
all other implementations, but then its performance drops down at 32 threads.
The reason could be that this implementation is
optimized for full scans or very big range queries running sequentially.
The overhead of initiating an epoch per range query---waiting for all
pending update operations to complete---prevents them from scaling when 
several queries are executed in parallel. This is even more prevalent when the
ranges are small (Figure~\ref{evaluation:results:range}), and the throughput of
\bronson flattens out. 
  
In addition, the lazy cloning required to support
range queries imposes an overhead on the update operations. Copying each node
during downward traversal prevents these operations from scaling when
the ranges are small (Figure~\ref{evaluation:results:update}) as well as when
they are big (Figure~\ref{evaluation:results:update1000}).
