\section{Evaluation}\label{sec:eval}

\paragraph{Implementation Details}
We implemented our automatic transformation in Java$^{TM}$, 
the following section highlight some technical details of 
the implementation.

Version numbers were added as a field in each object, 
incremented inside an acquire function. The
locked set and the read set can be implemented using several Java 
provided data structures. We chose to use arrays as they provide low 
overheads. Timeouts were implemented using a counter, incremented and checked
inside loops (backwards branches) and calls to functions.

Retries can be implemented using the exception mechanism,
that is already required to due to loss of internal consistency. 
However, this mechanism can hinder performance since retries occur 
more often than program exception. Instead we implemented an error mechanism
(inspired by C errno.h), an error object is sent to the operation from 
a wrapper function. If the operation needs to restart it sets the error and
returns. The wrapper checks the error object, if it is set the operation
is called again with a clean error object, otherwise the wrapper returns 
the operation return value. This wrapper is also used to count the retries
and fall back to the full locking protocol.

Operations were delimited with catch blocks, if an exception
is caught a read set validation takes place, 
if the read set validation passes it means that the exception  is inherent
to the original program and is thrown to higher levels, otherwise, the
exception might occurred due to unvalidated reads and the operation is
restarted. 

\paragraph{Setup}
In order to apply our approach to a data structure, a
''black-box'' pessimistic locking is required. One such 
approach was presented in \cite{Gueta2011}, automatically 
applying domination locking protocol to forest based data structures.  
We applied domination locking followed by our optimistic 
transformation to two tree based data structures, 
a simple unbalanced binary search tree 
and a treap (randomized binary search tree) \cite{AragonS1989}.

We compared the performance of our automatic implementations, 
the automatic binary search tree (\autoTree) and the automatic
treap (\autoTreap), to the following custom tailored approaches: 
\begin{itemize}
\item \danaTree - The locked-based 
				unbalanced tree of Drachsler at al.\cite{DrachslerVY2014}
				\footnote{Implementation provided by the authors}. 
\item \danaAVL - The locked-based relaxed balanced AVL tree of 
				Drachsler et al.\cite{DrachslerVY2014}
				\footnote{Implementation available at \\
				\texttt{https://github.com/logicalordering/trees}} .
\item \bronson - The locked based relaxed balanced AVL tree
				of Bronson et al.\cite{BronsonCCO2010}
				\footnote{Implementation available at \\
				\texttt{https://github.com/nbronson/snaptree}}.
\item \skiplist - The non-blocking skip-list by Doug 
				Lea included in the 
				the Java standard library.
\end{itemize}

We also compared our algorithms to previous automatic approaches, 
mainly global locking (\globalTree, \globalTreap) 
and domination locking (\domTree, \domTreap). 

We ran our experiments on four Inter Xeon E-4650 processors, 
each with 8 cores for a total of 32 threads 
(with hyper-threading disabled). 
We used Ubuntu 12.04.4 LTS and Java$^{TM}$ Runtime Environment (build
1.7.0\_51-b13) using the 64-Bit Server VM (build 24.51-b03, mixed mode).


We evaluated the performance on a variety of workloads, 
each workload is defined by the percentage of read-only
operations (\getOP queries) and the remaining operations 
are divided equally between insert and delete operations.
Our workloads include heavy read-only workloads
(100\% \getOP operations), medium read-only workload 
(50\% \getOP operations) and update only workload
(0\% \getOP operations). 

We used two key ranges $[0,2\cdot10^4]$ and $[0,2\cdot10^6]$,
for each range, the tree was pre-filled until the tree size was 
within 5\% of half the key range.   

We ran five seconds trials measuring the total throughput
(number of operations per second) of all threads.
During the trial, each thread continuously executed randomly
chosen operations according to the workload distribution 
using uniformly random keys from the key range.  
We ran every trial 7 times, we report the average throughput
while eliminating outliers.

\paragraph{Results} Figure \ref{evaluation:results:unbalanced} 
reports the throughput of unbalanced data structures and Figure 
\ref{evaluation:results:balanced} reports
the throughput of the balanced data structures. 
The results for the read-only workload show the main overhead
of our automatic approach. Unlike the hand crafted implementations
that have no overhead on reads in this scenario, either by wait free reads in
\danaTree and \danaAVL or the optimistic validation of \bronson, 
our implementation requires full \readSet validation.
This overhead cannot be avoided without prior knowledge on the
data structure.
%, however, given knowledge on the semantics of
%the data structure a small modification to the automatic code 
%can be applied. 
%For example, we took the \autoTree and removed 
%the \readSet validation for a \getOP operation
%that found the required key. The new operation immediately returns 
%the value without the any validation. 
%Correctness in maintained because if an operation finds the node then
%it is reachable at some configuration during the operation interval, 
%given that the insert operation is correct 
%(never adds a node to detached part of the tree).
%The results of the new optimized code can be found in \ldots 
 
As the update workload increases our automatic implementation 
closes this gap, and for some operation distributions and 
key ranges even outperforms some of the hand crafted algorithms.
These results show that our automatic transformation is highly optimized for
high update contention. This is probably due to the fact that once
an update phase is started the operation is not delayed due to concurrent 
read operations. 

Additionally, the results show that our automatic transformation 
works better on larger data structures. In large data structures 
update operations are more likely to operate on disjoint parts of 
the data, allowing high concurrency. This is especially important 
for the automatic transformation as updates  with overlapping 
locked sets might invalidate each other.  
 


\begin{figure*}
\begin{center}
\input{plots/unbalanced}
\end{center}
\caption{Throughput of unbalanced data
structures.
y-axis show the throughput (operations/sec), 
and x-axis show the number of threads.
\label{evaluation:results:unbalanced}}
\end{figure*}


\begin{figure*}
\begin{center}
\input{plots/balanced}

\end{center}
\caption{Throughput of balanced data
structures.
y-axis show the throughput (operations/sec), 
and x-axis show the number of threads.
\label{evaluation:results:balanced}}
\end{figure*}