\section{Evaluation}\label{sec:eval}

\Xomit{
\paragraph{Implementation Details}
We implemented our automatic transformation in Java$^{TM}$, 
the following section highlight some technical details of 
the implementation.

Version numbers were added as a field in each object, 
incremented inside an acquire function. The
locked set and the read set can be implemented using several Java 
provided data structures. We chose to use arrays as they provide low 
overheads. Timeouts were implemented using a counter, incremented and checked
inside loops (backwards branches) and calls to functions.

Retries can be implemented using the exception mechanism,
that is already required to due to loss of internal consistency. 
However, this mechanism can hinder performance since retries occur 
more often than program exception. Instead we implemented an error mechanism
(inspired by C errno.h), an error object is sent to the operation from 
a wrapper function. If the operation needs to restart it sets the error and
returns. The wrapper checks the error object, if it is set the operation
is called again with a clean error object, otherwise the wrapper returns 
the operation return value. This wrapper is also used to count the retries
and fall back to the full locking protocol.

Operations were delimited with catch blocks, if an exception
is caught a read set validation takes place, 
if the read set validation passes it means that the exception  is inherent
to the original program and is thrown to higher levels, otherwise, the
exception might occurred due to unvalidated reads and the operation is
restarted. 
}

\paragraph{Setup}
In order to apply our approach to a data structure, a
black-box pessimistic locking scheme is required. One such 
approach, presented in \cite{Gueta2011}, automatically 
applies domination locking  to forest-based data structures.  
We follow this approach, and apply a domination locking protocol
followed by our transformation presented in Section~\ref{sec:algorithm}. 
We synthesized concurrent code from two example tree-based 
sequential data structures implemented in Java$^{TM}$: 
a simple unbalanced binary search tree, 
and a treap (randomized binary search tree) \cite{AragonS1989}.
We call the resulting data structures 
automatic binary search tree (\autoTree) and  automatic
treap (\autoTreap), respectively.

We compare the performance of these  automatic implementations
to the following custom tailored approaches: 
\begin{itemize}
\item \danaTree - The locked-based 
				unbalanced tree of Drachsler at al.~\cite{DrachslerVY2014}\footnote{Implementation provided by the authors.}. 
\item \danaAVL - The locked-based relaxed balanced AVL tree of 
				Drachsler et al.~\cite{DrachslerVY2014}\footnote{Implementation available at \\
				\texttt{https://github.com/logicalordering/trees}}.
\item \bronson - The locked based relaxed balanced AVL tree
				of Bronson et al.~\cite{BronsonCCO2010}\footnote{Implementation available at \\
				\texttt{https://github.com/nbronson/snaptree}}.
\item \skiplist - The non-blocking skip-list by Doug 
				Lea included in the 
				the Java$^{TM}$ standard library.
\end{itemize}

We further compare our algorithms to previous automatic approaches, 
namely global locking (\globalTree, \globalTreap) 
and domination locking (\domTree, \domTreap). 

We run our experiments on four Intel Xeon E5-4650 processors, 
each with 8 cores for a total of 32 threads 
(with hyper-threading disabled). 
We used Ubuntu 12.04.4 LTS and Java$^{TM}$ Runtime Environment (build
1.7.0\_51-b13) using the 64-Bit Server VM (build 24.51-b03, mixed mode).


We evaluate performance on a variety of workloads;
each workload is defined by the percentage of read-only
operations (\emph{contains} queries), whereas the remaining operations 
are divided equally between insert and delete.
Our workloads include heavy read-only workloads
(100\% contains operations), medium read-only workloads 
(50\% contains operations) and update only workloads
(0\% contains operations). 

We also consider two sizes of data structures, by using two key ranges
$[0,2\cdot10^4]$ and $[0,2\cdot10^6]$, for each range, the tree is pre-filled until the tree size is 
within 5\% of half the key range.   

We run five seconds trials measuring the total throughput
(number of operations per second) of all threads.
During the trial, each thread continuously executes randomly
chosen operations according to the workload distribution, 
using uniformly random keys from the key range.  
We ran every trial 7 times, and report the average throughput
after eliminating outliers.

\paragraph{Results} Figure \ref{evaluation:results:unbalanced} 
reports the throughput of unbalanced data structures and Figure 
\ref{evaluation:results:balanced} presents
the throughput of the balanced ones. We see that our semi-optimistic
solution is far superior to previous, fully-pessimistic, 
automated approaches. It successfully overcomes the bottlenecks
associated with lock contention, and in many scenarios comes close
to custom-tailored implementations.

The results for the read-only workload show the main overhead
of our automatic approach. By profiling the code, we learned 
that the bulk of this overhead stems from the need to track all read objects,
which is inherent to our automatic transformation. 
This is in contrast with the hand-crafted implementations,
which have no overhead on reads in this scenario, thanks to either 
wait-free reads (in \danaTree and \danaAVL), or optimistic validation (in \bronson). 
%, however, given knowledge on the semantics of
%the data structure a small modification to the automatic code 
%can be applied. 
%For example, we took the \autoTree and removed 
%the \readSet validation for a \getOP operation
%that found the required key. The new operation immediately returns 
%the value without the any validation. 
%Correctness in maintained because if an operation finds the node then
%it is reachable at some configuration during the operation interval, 
%given that the insert operation is correct 
%(never adds a node to detached part of the tree).
%The results of the new optimized code can be found in \ldots 
 
As the ration of updates in the workload increases, our automatic implementation 
closes this gap, and for some operation distributions and 
tree sizes even outperforms some of the hand-crafted algorithms.
These results show that our automatic transformation deals well with update contention. 
This is probably due to the fact that once
an update phase begins, the operation is not delayed due to concurrent 
read-only operations. 

Additionally, the results show that our automatic transformation 
works better on larger data structures. Indeed, in large data structures, 
update operations are more likely to operate on disjoint parts of 
the data, allowing high concurrency. This is especially important 
for the automatic transformation as updates  with overlapping 
locked sets might invalidate each other.  
 


\begin{figure*}
\begin{center}
\input{plots/unbalanced}
\end{center}
\caption{Throughput of unbalanced data
structures.
\label{evaluation:results:unbalanced}}
\end{figure*}


\begin{figure*}
\begin{center}
\input{plots/balanced}


\end{center}
\caption{Throughput of balanced data
structures.
\label{evaluation:results:balanced}}
\end{figure*}