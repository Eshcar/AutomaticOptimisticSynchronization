\section{Model and Definitions}\label{sec:model}


\paragraph{Shared Memory Data Structures}

We consider an asynchronous shared memory model, where independent threads interact via shared memory objects.
For the sake of our discussion, we do not distinguish among different types of shared memory (e.g., global or heap-allocated).
In addition, each thread has access to \emph{local} (thread-local) memory.

A \emph{data structure} is an abstract data type exporting a set of \emph{operations}.
A data structure is implemented from a collection of primitive shared
\emph{objects} (variables) supporting atomic read (load) and write (store)
operations.
Below, we extend the allowed primitive objects to also include locks.

Every thread executes a sequence of operations, each of which is invoked with certain parameters and returns a response.
An operation's execution consists of a sequence of primitive \emph{steps}, beginning with an \emph{invoke} step, followed by
atomic accesses to shared objects, and ending with a \emph{return} step. Steps also modify the executing thread's local variables.

A \emph{configuration} is an assignment of values to all shared and local variables. Thus, each step takes the system from one
configuration to another. Steps are deterministically defined by the data structure's protocol and the current configuration.
In the \emph{initial configuration}, each variable holds its initial value.

An \emph{execution} is an alternating sequence of configurations and steps,
$C_0,s_1,C_1, \ldots,s_i,C_i,\ldots,$
where $C_0$ is an initial configuration,
and each configuration $C_i$ is the result of
executing step $s_i$ on configuration $C_{i-1}$.
An execution is \emph{sequential} if steps of different operations are not interleaved.
In other words, a sequential execution is a sequence of operation executions.

\paragraph{Locking Protocols}
%\label{ssec:locking}

A \emph{lock} is a primitive type that supports atomic \emph{lock},
\emph{tryLock}, \emph{unlock} and \emph{isLocked} operations, where tryLock is a
non-blocking attempt to acquire a lock that may fail.

We assume in this paper an existing (black box) locking mechanism, which transforms a sequential data-structure to a concurrent (thread-safe)
one by adding locks:
it associates a lock with every primitive shared object used by the data structure, and instruments the sequential code
by adding lock and unlock operations.
The locks are added so as to abide to some set of rules, called a \emph{locking protocol}.
Examples of such protocols are two-phase locking~\cite{Eswaran:1976}, tree locking~\cite{SilberschatzK1980}, and domination locking~\cite{Gueta2011}.

We note that there are known code transformations that satisfy certain locking protocols (e.g., domination locking~\cite{Gueta2011}), but no known
transformation for others; the question of developing such transformations is orthogonal to our contribution in this paper.
In our implementation, we use domination locking, which is restricted to tree-like data structures.
Intuitively, the domination locking protocol automatically performs some sort of ``hand-over-hand'' locking, acquiring locks as
it traverses a linked-list or tree, and releasing locks held on previously traversed nodes.

We assume that in the resulting code (obtained by adding the locks) every (read
or write) access by an operation to a shared object is performed when the
executing thread holds the lock on that object.

%We assume that the resulting code (obtained by adding the locks) satisfies the following properties:
%\begin{itemize}
%\item Every (load or store) access by an operation to a shared object is performed when the executing thread holds the lock on that object.
%\item The protocol is deadlock-free, i.e., locking does not introduce deadlocks.
%\end{itemize}

\paragraph{Correctness}

The correctness of a data structure is defined in terms of its external behavior, as reflected in values returned by invoked operations.
Correctness of a code transformation is proven by showing that the synthesized code's executions are equivalent to ones of the original code,
where two executions are  \emph{equivalent} if every thread invokes the same
operations in the same order  in both executions, and gets the same result for each operation. More formally, we say in this paper that a code transformation is \emph{correct} if every execution of the transformed code
is equivalent to some execution of the original code.

The widely-used correctness criterion of serializability relies on equivalence to sequential executions in order to
link a data structure's behavior under concurrency to its sequentially specified behavior. Since equivalence is transitive,
we get that any code transformation satisfying our correctness notion, when applied to serializable code, yields code that is also serializable.
If the code transformation further ensures the real-time order of operations (that is, operations that do not overlap appear in the same order in the
histories of the transformed and original code), then linearizability (atomicity) is also invariant under the transformation.

In this paper, we are not concerned with internal consistency (as required e.g., by opacity~\cite{GuerraouiK2008} or the validity notion of~\cite{LevAriCK2014}),
which restricts the configurations an operation might see during its execution.
This is because our code transformation uses timeouts and exception handlers to overcome unexpected behavior that may arise when a thread sees an inconsistent view of global variables (similar to~\cite{Nakaike:2010}).

