\section{Evaluation}
\label{sec:eval}

We evaluate the performance of our approach on two types of data
structures. In Section~\ref{sec:readwrite} we consider search trees
supporting insert, delete, and get operations, whereas Section~\ref{sec:range}
focuses on data structures that, in addition, support range queries that retrieve all
keys within a given range. We compare the performance of our approach in terms of
throughput to fully pessimistic solutions applying fine-grain locking. These
algorithms also serve as the lock-based reference implementation at the base of
our semi-optimistic implementations.
We further
compare our approach to software transactional memory and hand-crafted state-of-the-art data structure
implementations supporting the same functionality.

We also measured the performance of global lock-based implementations.
In all workloads, the results were identical or inferior to those
achieved by pessimistic fine-grain locking. We hence
omitted these results to avoid obscuring the presentation.

We use the micro-benchmark suite \textit{Synchrobench}~\cite{Gramoli2015}, configured as described below. 
%We follow a standard evaluation methodology
%(\cite{DrachslerVY2014,NatarajanM2014,BrownER2014,ArbelA2014}). 
Each experiment
consists of $5$ trials. A trial is a five second run in which each thread continuously executes
randomly chosen operations drawn from the workload distribution, with keys
selected uniformly at random from the range $[0,2\cdot10^6]$.
Each trial begins by initiating a new data structure with
%and applying an untimed pre-filling phase, which continues until the size of the data structure is within 5\% of
$10^6$ records. The presented results are the average throughput over all trials.
%(with the pre-filling phase excluded).

All implementations are written in Java. We ran the experiments on a dedicated machine with
four Intel Xeon E5-4650 processors, each with $8$ cores, for a total of $32$ threads
(with hyper-threading disabled).
We used Ubuntu 12.04.4 LTS and Java Runtime Environment (build
1.7.0\_51-b13) using the 64-Bit Server VM (build 24.51-b03, mixed mode).

\subsection{Insert-Delete-Get Operations}
\label{sec:readwrite}

We start by benchmarking a search-tree supporting the basic insert,
delete, and get (lookup) operations. Our experiments evaluate unbalanced as well
as balanced trees.

We employ textbook sequential implementations of an unbalanced binary
tree, and a treap~\cite{AragonS1989}. To
generate pessimistic lock-based implementations, we synthesize
concurrent code by applying the domination locking technique to the sequential
data structures. The resulting algorithms are denoted \domTree and \domTreap.
Finally, we manually apply our lock-removal transformation to the reference
implementations to get our semi-optimistic versions of the code, which we call
\autoTree and \autoTreap, respectively.
We also applied Deuce~\cite{Deuce2010}, which is a Java implementation of the TL2 algorithm~\cite{DiceSS2006} to the sequential implementations. The resulting algorithms are denoted \stmTree and \stmTreap.

We further compare our implementations to their hand-crafted state-of-the-art counterparts\footnote{Unless described otherwise implementations are provided by Synchrobench}. We compare \autoTree to
\begin{description}
\setlength{\itemsep}{0pt}
\setlength{\parskip}{0pt}
\item[\danaTree] The locked-based unbalanced tree of Drachsler et al.~\cite{DrachslerVY2014}\footnote{Implementation provided by the authors.}.
\item [\lockfreeTree] The lock-free unbalanced tree of Ellen et al.~\cite{EllenFRB2010}.
\end{description}
\autoTreap is evaluated against three hand-crafted implementations
\begin{description}
\setlength{\itemsep}{0pt}
\setlength{\parskip}{0pt}
\item[\danaAVL] The locked-based relaxed balanced AVL tree of
				Drachsler et al.~\cite{DrachslerVY2014}.%\footnote{Implementation available at \\\texttt{https://github.com/logicalordering/trees}}.
\item[\bronson] The locked based relaxed balanced AVL tree
				of Bronson et al.~\cite{BronsonCCO2010}.%\footnote{Implementation available at \\texttt{https://github.com/nbronson/snaptree}}.
\item[\friendly] The Contention-Friendly Tree of Crain et al.~\cite{CrainGR2013}.
%\item[\skiplist] The non-blocking skip-list in the the Java standard library; based on the work of Fraser and Harris~\cite{fraser2004practical}.
\end{description}

We evaluate performance in three representative workloads distributions: a
\emph{read-only} workload comprised of $100\%$ lookup operations, a \emph{write-dominated}
workload consisting of insert and delete operations ($50\%$ each), and a
\emph{mixed workload} with $50\%$ lookups, $25\%$ inserts, and $25\%$
deletes.

\paragraph{Results}
Figure~\ref{evaluation:results:unbalanced}
shows the throughput of unbalanced data structures and Figure~\ref{evaluation:results:balanced} shows
the throughput of the balanced ones. We see that our semi-optimistic
solution is far superior to the previous, fully-pessimistic,
automated approach; it successfully overcomes the bottlenecks associated with lock contention
in the \domTree and \domTreap implementations. 

For both balanced and unbalanced trees, our approach outperforms STM with 2x to 3x throughput.
This might be due to the tradeoff between validation overhead vs not concerning with internal consistency.
To ensure opacity~\cite{GuerraouiK2008}, each time an object is read in STM, the transaction checks that the version of the lock protecting the object is valid. 
Our algorithms read the version instead of locking the object which happens less frequently, typically once during the operation.
This is where sandboxing pays off -- we allow operations to observe inconsistent views and hence have improved performance.


%In many scenarios, 
Our solution comes close to custom-tailored implementations.
The results for the read-only workload show the main overhead
of our automatic approach. By profiling the code, we learned
that the bulk of this overhead stems from the need to track all read objects,
which is inherent to our transformation.
This is in contrast with the hand-crafted implementations,
which have small overhead on reads in this scenario, thanks to either
wait-free reads (in \danaAVL, \danaTree, \friendly and \lockfreeTree ), or optimistic validation (in \bronson).

As the ratio of updates in the workload increases, our automatic implementation
closes this gap.
In other words, the transformed code deals well with update contention.
This might be due to the fact that once
an update phase begins, the operation is not delayed due to concurrent
read-only operations.

%% Eshcar: discuss small trees? the results are not the same
We also experimented with a smaller trees ($[0,2\cdot10^4]$) to test different
contention levels (the results appear in Appendix~\ref{appendix:results}).
The results show that our transformation works better on larger data structures. 
Indeed, in large data structures, update operations are more likely to operate on disjoint parts
of the data, allowing high concurrency. 
%This is especially important for the automatic transformation as updates with overlapping lock sets might invalidate each other.
%; since the results showed similar trends, they are omitted here.

\subsection{Range Queries}
\label{sec:range}

Next we evaluate the performance of our approach when the data
structure supports a more intricate functionality like range queries.
\Xomit{
Hand
crafting an implementation of a data structure that supports atomic
(linearizable) range queries is challenging.
The implementations that do support iterating through records may impose an
additional overhead on the regular read and write operations to ensure
progress of range queries.
The results in this section demonstrate that our method
allows generating a correct and efficient code, which is otherwise difficult
to obtain.
}
We use a skip list, which readily supports range queries by
nature of its linked-structure. The core of the implementation is the key lookup
method; once reaching the key, a record can be added or be removed in place, and
an iteration of subsequent records can be executed by traversing
the bottom-level linked-list.

The domination locking scheme cannot be efficiently applied to the skip list
structure since it is a DAG rather than a tree. Instead, we
manually devise a pessimistic locking protocol. Our
algorithm, (inspired by the one in~\cite{HerlihyS2008}), applies
hand-over-hand locking at each level, so that at the end of the search, the
operation holds locks on two records in each level, which define the minimal interval within this level
containing the lookup key (or the first lookup key in the case of a range query). Upon
reaching the bottom level, unnecessary locks are released, as follows: update operations only keep
locks on nodes they intend to modify, whereas
%that will be modified; while holding these locks any
%modification can be executed in isolation from other update operations.
range
queries keep the locks in the level with the minimal interval spanning the
range. Range queries then continue to use hand-over-hand locking to traverse through all records
within the range. The use of hand-over-hand locking ensures that range queries are atomic
(linearizable), i.e., return a consistent view of the data structure.

This pessimistic lock-based algorithm is denoted \domSkiplist.
As in previous data structures, we  apply the lock-removal transformation to the
reference implementation to get a semi-optimistic algorithm, which we call
\autoSkiplist.

We also applied Deuce to the skip-list sequential implementation. The resulting algorithm is denoted \stmSkiplist.

Our approach is also compared to the aforementioned
state-of-the-art data structures that support range queries. Specifically,
we compare \autoSkiplist to 
\begin{description}
\setlength{\itemsep}{0pt}
\setlength{\parskip}{0pt}
\item[\skiplist] The non-blocking Java skip-list which supports \emph{non}-linarizable range queries through iterators.
\item[\kary] A linearizable, non-blocking $k$-ary search tree
that supports range queries~\cite{BrownA12}\footnote{\url{http://www.cs.toronto.edu/~tabrown/kstrq}}.
%\item[\bronson] provides atomic range queries by traversing a clone of the
%original tree that is lazily generated
\end{description}
To ensure a fair comparison (following~\cite{BrownA12}) the range query operation in all implementations return an array of keys.
For \skiplist this means projecting a subset of the keys, iterating over them, and then copying each of these keys into an array. This does not include a snapshot, so range queries are
not always linearizable. \kary is similar to a b-tree, where the degree of the nodes is at most $k$. In our experiments we set $k$ to 64.

Like many data structure libraries, \friendly and \danaAVL
do not support atomic range queries, and
there is no straightforward way to add them.



% \begin{figure*}
% \begin{center}
% \input{plots/range}
% \end{center}
% \caption{Throughput of skip-list operations.}
% \label{evaluation:results:range}
% \end{figure*}


\begin{figure*}
\begin{center}
\input{plots/unbalanced3}
\end{center}
\caption{Throughput of unbalanced data structures.}
\label{evaluation:results:unbalanced}
\end{figure*}

\Xomit{
\begin{figure*}
\begin{center}
\input{plots/unbalanced3small}
\end{center}
\caption{Throughput of unbalanced data structures. Small Tree. }
\label{evaluation:results:unbalanced}
\end{figure*}
}

\begin{figure*}
\begin{center}
\input{plots/balanced3}
\end{center}
\caption{Throughput of balanced data
structures.}
\label{evaluation:results:balanced}
\end{figure*}

\Xomit{
\begin{figure*}
\begin{center}
\input{plots/balanced3small}
\end{center}
\caption{Throughput of balanced data
structures. Small Tree.}
\label{evaluation:results:balanced}
\end{figure*}
}

\Xomit{
\begin{figure*}
	\begin{center}
	\begin{{subfigure}[t]{.35\textwidth}
		\caption{Range queries}
		\input{plots/skiplists}
		\label{evaluation:results:skiplist:scans}
	\end{subfigure}
	\quad\quad
	\begin{subfigure}[t]{.35\textwidth}
		\caption{Insert and delete operations}
		\input{plots/skiplists}
		\label{evaluation:results:skiplist:updates}
	\end{subfigure}
	\ref{skiplistLegened}
	\end{center}
\caption{Small range: all threads execute either small range queries $[10,20]$
or a mix of insert and delete operations.}
\label{evaluation:results:skiplist}
\end{figure*}
}
}

\begin{figure*}
\begin{center}
\input{plots/smallrangeAll}
\end{center}
\caption{Small range: all threads execute either small range queries $[10,20]$
or a mix of insert and delete operations.}
\label{evaluation:results:skiplist}
\end{figure*}

\Xomit{
\begin{figure*}
	\begin{center}
	\begin{subfigure}[t]{.35\textwidth}
		\caption{Range queries}
		\input{plots/range}
		\label{evaluation:results:range}
	\end{subfigure}
	\quad\quad
	\begin{subfigure}[t]{.35\textwidth}
		\caption{Insert and delete operations}
		\input{plots/update}
		\label{evaluation:results:update}
	\end{subfigure}
	\ref{skiplistLegened}
	\end{center}
\caption{Small range: half the threads execute small range queries $[10,20]$
and half the threads execute insert and delete operations.}
\label{evaluation:results:skiplist10}
\end{figure*}

\begin{figure*}
	\begin{center}
	\begin{subfigure}[t]{.35\textwidth}
		\caption{Range queries}
		\input{plots/range1000}
		\label{evaluation:results:range1000}
	\end{subfigure}
	\quad\quad
	\begin{subfigure}[t]{.35\textwidth}
		\caption{Insert and delete operations}
		\input{plots/update1000}
		\label{evaluation:results:update1000}
	\end{subfigure}
	\ref{skiplistLegened1000}
	\end{center}
\caption{Half the threads execute large range queries $[1000,2000]$
and half the threads execute insert and delete operations.}
\label{evaluation:results:skiplist1000}
\end{figure*}
}



\paragraph{Results}
We start the evaluation of data structures supporting range queries (Figure~\ref{evaluation:results:skiplist}) with the read-only workload, where all threads execute small range queries between $10$ to $20$ keys. 
%The results reflect the correlation of the implementation to scan-only workload. 
As expected, \kary has the best performance as it is optimal for batch scans. The simplicity of the non-linearizable implementation of \skiplist allows it to perform well. Our semi-optimistic transformed code, outperforms both the STM and the fully-pessimistic fine-grain transformations.

On the other extrem, we evaluated all updates (write-dominated) workloads, where the operations are a mix of insert and delete operations (50\% each). Here, splitting and merging nodes affect the performance of \kary which flattens out at 32 threads. The throughput of \autoSkiplist and \stmSkiplist are comparable, both scale nicely with the number of threads.
Again, we see that \autoSkiplist outperforms
  to the fully-pessimistic fine-grain one. We believe that,
as in the
domination locking versions of the tree data structures, holding a lock on the head sentinel of the skip list in
\domSkiplist, even for short periods, imposes a major performance penalty,
which is eliminated by our semi-optimistic approach. 
Finally, \autoSkiplist is also superior to the STM implementation
improving throughput by
10x. The improvement in update operations can be attributed to lack of contention on a centralized object like the global version in \stmSkiplist.

Next, we focus on a mixed workload, where half the
threads are dedicated to performing range queries, and the other half perform a
mix of insert and delete operations (50\% each).
This mix allows us to evaluate both the performance of the range queries,
and their impact on concurrent updates and vice versa.
Indeed, the results show that \kary's throughput for range query is comarable to that of \skiplist, and at 32 thread have througput similar to \autoSkiplist.

We also experimented with mixed workloads for large queries with large ranges varying between $1000$ to $2000$ keys (the results appear in Appendix~\ref{}). Here the impact of concurrent update operations on range queries is most pronounced in the results of \kary.

\Xomit{
The evaluation of range queries focuses on a mixed workload, where half the
threads are dedicated to performing range queries, and the other half perform a
mix of insert and delete operations (50\% each).
This mix allows us to evaluate both the performance of the range queries,
and their impact on concurrent updates and vice versa.
%\eshcar{what about a workload that includes only 100\% range
%queries?}
We experiment with queries with large ranges varying between $1000$ to $2000$ keys
(Figure~\ref{evaluation:results:skiplist1000}) and small ranges
between $10$ to $20$
keys (Figure~\ref{evaluation:results:skiplist10}).

We measure the throughput of range queries and update operations separately.
The overall number of range queries executed per second is reported
in Figures~\ref{evaluation:results:range1000}
and~\ref{evaluation:results:range}, and the overall number of update (insert
and delete) operations executed per second is reported in
Figures~\ref{evaluation:results:update1000} and~\ref{evaluation:results:update}.

Again, we see that our transformed code outperforms
  to the fully-pessimistic fine-grain one. We believe that,
as in the
domination locking versions of the tree data structures, holding a lock on the head sentinel of the skip list in
\domSkiplist, even for short periods, imposes a major performance penalty,
which is eliminated by our  semi-optimistic approach.

It is superior also to the STM implementation
improving throughput by
up to three orders of magnitude -- 500x for large range queries, 2x for small
ranges, and 10x for update operations, regardless of the range size. The improvement in update operations can be attributed to lack of contention on a centralized object like the global version in \stmSkiplist. \eshcar{explain difference in range queries}


The simplicity of the non-linearizable implementation of \skiplist allows it to perform better than \autoSkiplist on range queries.  However, the performance of
\autoSkiplist is almost identical to that of \skiplist --and even better in some cases, when comparing the update operations.
%despite the fact that \skiplist performs inconsistent iterations.
}
\Xomit{
Figure~\ref{evaluation:results:range1000}
shows that, for large ranges, \bronson scales well up to $8$ threads, outperforming
all other implementations, but at $32$ threads its performance deteriorates.
This might be because this implementation is
optimized for full scans or very large range queries running sequentially.
The overhead of initiating a clone of the data structure per range query, which
involves waiting for all
pending update operations to complete, hampers scalability when
a number of queries are executed in parallel. This effect is even more pronounced when the
ranges are small (Figure~\ref{evaluation:results:range}), and the throughput of
\bronson flattens out.

In addition, the lazy cloning required to support
range queries imposes an overhead on  update operations. Copying each node
during downward traversal might be the main impediment preventing these
operations from scaling when the ranges are small (Figure~\ref{evaluation:results:update}) as well as when
they are large (Figure~\ref{evaluation:results:update1000}). In contrast,
the update operations in \autoSkiplist and \skiplist do not take any special
measures for the benefit of concurrent queries (which validate themselves in
\autoSkiplist, and are not atomic in \skiplist), and hence continue to perform well in
their presence.
}
